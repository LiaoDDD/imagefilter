#train for light source model
import os
import glob
import random
import numpy as np
import pandas as pd
from PIL import Image
from tqdm import tqdm
import torch
import torch.nn as nn
from torch.utils.data import Dataset, DataLoader
import torchvision.transforms as transforms
import torchvision.models as models
import torch.optim as optim
from sklearn.metrics import classification_report
from argparse import ArgumentParser

parser = ArgumentParser()
parser.add_argument(
    "--data-root",
    help="根目錄（例如 data/UDC-SIT），其中應包含 training, validation 資料夾及標註 csv。",
    default="/app/test/data/UDC-SIT",
)
parser.add_argument(
    "--batch-size",
    type=int,
    default=32,
    help="每個 mini-batch 的樣本數",
)
parser.add_argument(
    "--num-epochs", type=int, default=20, help="訓練 epoch 數量"
)
parser.add_argument(
    "--lr", type=float, default=1e-4, help="學習率"
)
# 使用 parse_known_args 以忽略 Jupyter Notebook 自動傳入的多餘參數
args, unknown = parser.parse_known_args()

# 路徑設定
###############################
data_root = args.data_root
train_dir = os.path.join(data_root, "training")
val_dir = os.path.join(data_root, "validation")
annotation_file = os.path.join(data_root, "annotation_udc_sit.csv")

# 設定 device（有 GPU 則使用 GPU）
###############################
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# 定義影像轉換（預處理）
###############################
data_transforms = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406],
                         std=[0.229, 0.224, 0.225])
])

# 自訂 Dataset 類別
###############################
class UDCSITDataset(Dataset):
    def __init__(self, annotation_csv, subset="training", subfolders=["GT", "input"], transform=None):
        """
        annotation_csv: 標註 CSV 文件路徑，內容必須包含 Filename, Dataset, LightSource 等欄位
        subset: "training" 或 "validation"
        subfolders: 可能存圖片的子資料夾列表（例如 GT 與 input）
        transform: 對讀取的 PIL Image 執行轉換操作
        """
        self.df = pd.read_csv(annotation_csv)
        # 過濾指定子集的資料
        self.df = self.df[self.df["Dataset"] == subset]
        self.subfolders = subfolders
        self.transform = transform
        # 依據 Filename 欄位，假設檔案名稱為 "<Filename>.npy"
    
    def __len__(self):
        return len(self.df)
    
    def __getitem__(self, idx):
        row = self.df.iloc[idx]
        filename = str(row["Filename"]) + ".npy"
        # 從提供的子資料夾中尋找檔案，優先找 GT，如果沒有再找 input
        filepath = None
        for sub in self.subfolders:
            # 根據子集選擇 training 或 validation 資料夾
            base_dir = train_dir if row["Dataset"] == "training" else val_dir
            temp_path = os.path.join(base_dir, sub, filename)
            if os.path.exists(temp_path):
                filepath = temp_path
                break
        if filepath is None:
            raise FileNotFoundError(f"檔案 {filename} 不存在於指定子資料夾中。")
        
        # 讀取 .npy 檔案，並正規化 (除以 1023)
        img = np.load(filepath) / 1023.0
        # 假設 img 形狀為 (H, W, 4)，僅取前三個通道 (RGB)
        if img.shape[-1] >= 3:
            img = img[..., :3]
        else:
            raise ValueError(f"檔案 {filename} 的通道數不足3")
        # 將 numpy 陣列轉為 uint8 後建立 PIL Image
        img_uint8 = (img * 255).astype(np.uint8)
        pil_img = Image.fromarray(img_uint8)
        if self.transform:
            pil_img = self.transform(pil_img)
        label = int(row["LightSource"])
        return pil_img, label

# 建立 Dataset 與 DataLoader
###############################
train_dataset = UDCSITDataset(annotation_csv=annotation_file, subset="training",
                              subfolders=["GT", "input"], transform=data_transforms)
val_dataset = UDCSITDataset(annotation_csv=annotation_file, subset="validation",
                              subfolders=["GT", "input"], transform=data_transforms)

print("訓練集樣本數:", len(train_dataset))
print("驗證集樣本數:", len(val_dataset))

train_loader = DataLoader(train_dataset, batch_size=args.batch_size, shuffle=True, num_workers=0)
val_loader = DataLoader(val_dataset, batch_size=args.batch_size, shuffle=False, num_workers=0)

# 定義模型：使用預訓練的 ResNet18 並修改最後一層
###############################
model = models.resnet18(pretrained=True)
num_ftrs = model.fc.in_features
model.fc = nn.Linear(num_ftrs, 4)  # 4 類：無光、自然光、人工光、混合光
model = model.to(device)

# 定義訓練設定：損失函數、優化器、學習率調度器
###############################
criterion = nn.CrossEntropyLoss()  # 多分類交叉熵損失
optimizer = optim.Adam(model.parameters(), lr=args.lr)
scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.1)

# 定義訓練函數
###############################
def train_model(model, train_loader, val_loader, criterion, optimizer, scheduler, num_epochs, device):
    best_val_acc = 0.0
    for epoch in range(num_epochs):
        model.train()
        running_loss = 0.0
        correct_train = 0
        total_train = 0
        for inputs, labels in tqdm(train_loader, desc=f"Train Epoch {epoch+1}"):
            inputs, labels = inputs.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(inputs)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            
            running_loss += loss.item() * inputs.size(0)
            _, preds = torch.max(outputs, 1)
            correct_train += torch.sum(preds == labels.data)
            total_train += labels.size(0)
        
        epoch_loss = running_loss / total_train
        epoch_acc = correct_train.double() / total_train
        
        # 在驗證集上評估
        model.eval()
        correct_val = 0
        total_val = 0
        with torch.no_grad():
            for inputs, labels in tqdm(val_loader, desc=f"Val Epoch {epoch+1}"):
                inputs, labels = inputs.to(device), labels.to(device)
                outputs = model(inputs)
                _, preds = torch.max(outputs, 1)
                correct_val += torch.sum(preds == labels.data)
                total_val += labels.size(0)
        val_acc = correct_val.double() / total_val
        
        print(f"Epoch {epoch+1}/{num_epochs}  Loss: {epoch_loss:.4f}  Train Acc: {epoch_acc:.4f}  Val Acc: {val_acc:.4f}")
        
        scheduler.step()
        
        # 儲存最佳模型權重
        if val_acc > best_val_acc:
            best_val_acc = val_acc
            torch.save(model.state_dict(), "best_udcsit_model.pth")
    print("訓練完畢，最佳驗證準確率：", best_val_acc)

train_model(model, train_loader, val_loader, criterion, optimizer, scheduler, args.num_epochs, device)

# 評估模型：以驗證集輸出分類報告
###############################
def evaluate_model(model, data_loader, device):
    model.eval()
    all_preds = []
    all_labels = []
    with torch.no_grad():
        for inputs, labels in tqdm(data_loader, desc="Evaluating"):
            inputs, labels = inputs.to(device), labels.to(device)
            outputs = model(inputs)
            _, preds = torch.max(outputs, 1)
            all_preds.extend(preds.cpu().numpy())
            all_labels.extend(labels.cpu().numpy())
    return all_labels, all_preds

true_labels, pred_labels = evaluate_model(model, val_loader, device)
print("驗證集分類報告：")
print(classification_report(true_labels, pred_labels, target_names=["No Light", "Natural Light", "Artificial Light", "Mixed"]))

################################################################################
import requests
from io import BytesIO
from PIL import Image  
import torch
import torch.nn.functional as F
import matplotlib.pyplot as plt
import numpy as np

def predict_confident_from_url(model, image_url, transform, device, threshold=0.8, show_image=True):
    """
    根據 image_url 下載圖片，並根據模型對 Natural Light 與 Artificial Light 的輸出概率
    判斷模型信心，只有在最大概率大於等於 threshold 時才返回分類結果，
    否則返回 "Uncertain"。
    
    參數:
      model: 訓練完成的模型，輸出應為 4 類 logits
      image_url: 圖片的 URL
      transform: 與訓練時相同的圖片預處理流程
      device: 運行設備（例如 cpu 或 cuda）
      threshold: 信心門檻（例如 0.8 代表只有預測概率大於等於 80% 時才給出分類）
      show_image: 是否以 matplotlib 顯示圖片與標註
      
    回傳:
      預測結果字串，可能為 "Natural Light", "Artificial Light" 或 "Uncertain"
      並附帶最大機率數值。
    """
    # 下載圖片
    try:
        response = requests.get(image_url)
        response.raise_for_status()
    except Exception as e:
        raise RuntimeError(f"下載圖片失敗: {e}")
    
    # 解析圖片，確保轉為 RGB 模式
    try:
        pil_img = Image.open(BytesIO(response.content)).convert("RGB")
    except Exception as e:
        raise ValueError(f"解析圖片失敗: {e}")
    
    # 使用與訓練時相同的預處理步驟
    input_tensor = transform(pil_img)
    input_tensor = input_tensor.unsqueeze(0).to(device)
    
    model.eval()
    with torch.no_grad():
        output = model(input_tensor)
        # 計算 softmax 概率
        probs = F.softmax(output, dim=1)
        # 僅考慮目標類別：Natural Light (索引 1) 與 Artificial Light (索引 2)
        target_probs = probs[:, [1, 2]]
        max_prob, target_idx = torch.max(target_probs, dim=1)
        
    conf_value = max_prob.item()
    # 根據信心值決定返回的結果
    if conf_value < threshold:
        result_str = f"Uncertain (max prob: {conf_value:.2f})"
    else:
        if target_idx.item() == 0:
            result_str = f"Natural Light (max prob: {conf_value:.2f})"
        else:
            result_str = f"Artificial Light (max prob: {conf_value:.2f})"
    
    if show_image:
        # 將 PIL 圖片轉成 numpy 陣列以供 matplotlib 顯示
        img_np = np.array(pil_img)
        plt.figure(figsize=(6,6))
        plt.imshow(img_np)
        plt.axis('off')
        # 在圖片上標註文字，位置可依需求調整 (此處設定在左上角)
        plt.text(10, 30, result_str, color='red', fontsize=14,
                 bbox=dict(facecolor='black', alpha=0.7))
        plt.tight_layout()
        plt.show()
    
    return result_str

def predict_from_url_file(model, txt_filepath, transform, device, threshold=0.8, show_image=True):
    """
    讀取包含多個圖片 URL 的 TXT 檔案，依序下載、處理並進行預測，
    並根據設定的信心門檻只返回目標類別的分類結果。
    
    回傳:
      一個 dict: { url: 預測結果 }
      遇到下載或預測問題時，對應結果會為 Error 訊息。
    """
    results = {}
    try:
        with open(txt_filepath, "r") as f:
            urls = [line.strip() for line in f if line.strip()]
    except Exception as e:
        raise RuntimeError(f"讀取 URL 檔案失敗: {e}")
    
    for url in urls:
        try:
            result = predict_confident_from_url(model, url, transform, device, threshold=threshold, show_image=show_image)
            results[url] = result
        except Exception as e:
            results[url] = f"Error: {e}"
    
    return results

txt_filepath = "/app/test/urls_data.txt"

# 設定預測門檻（例如 0.7，代表只有預測概率大於等於 70% 時才給出分類結果）
threshold = 0.6

# 進行預測
predictions = predict_from_url_file(model, txt_filepath, data_transforms, device, threshold=threshold, show_image=True)

print("URL 圖片預測結果：")
for url, result in predictions.items():
    print(f"{url} --> {result}")
